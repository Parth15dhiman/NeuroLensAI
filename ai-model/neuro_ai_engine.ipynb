{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VMqTbRnKAx6W",
        "outputId": "99605f53-a051-4a63-9ca2-83dfad53d2ac"
      },
      "outputs": [],
      "source": [
        "# 1. Necessary Libraries\n",
        "!pip install transformers accelerate confluent-kafka torch torchvision facenet-pytorch opencv-python-headless numpy huggingface_hub\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from confluent_kafka import Consumer, Producer\n",
        "from facenet_pytorch import MTCNN\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aVYaNOMjx5Y-"
      },
      "outputs": [],
      "source": [
        "# 2. Setup & Authentication\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "secrets_dir = '/content/drive/MyDrive/NeuroLens_Certs/'\n",
        "config_file = os.path.join(secrets_dir, 'config.json')\n",
        "\n",
        "with open(config_file, 'r') as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "# Read token from environment variable\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "if HF_TOKEN is None:\n",
        "    raise RuntimeError(\"HF_TOKEN not found in environment variables\")\n",
        "\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "\n",
        "MODEL_ID = \"prithivMLmods/Deep-Fake-Detector-v2-Model\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 3. Load SOTA Model\n",
        "try:\n",
        "    print(f\"ðŸ”„ Loading SOTA Deepfake Model: {MODEL_ID}...\")\n",
        "    processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
        "    vit_model = AutoModelForImageClassification.from_pretrained(MODEL_ID).to(device)\n",
        "    vit_model.eval()\n",
        "    print(\"âœ… System Ready: High-Accuracy Mode Active.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Connection Error: {e}\")\n",
        "\n",
        "# 4. MTCNN & Kafka Setup\n",
        "mtcnn = MTCNN(image_size=224, margin=20, keep_all=False, device=device)\n",
        "\n",
        "\n",
        "conf = {\n",
        "    'bootstrap.servers': secrets['KAFKA_URI'],\n",
        "    'security.protocol': 'SSL',\n",
        "    'ssl.ca.location': os.path.join(secrets_dir, 'ca.pem'),\n",
        "    'ssl.certificate.location': os.path.join(secrets_dir, 'service.cert'),\n",
        "    'ssl.key.location': os.path.join(secrets_dir, 'service.key'),\n",
        "    'group.id': 'neurolens-fast-group',\n",
        "    'auto.offset.reset': 'latest',\n",
        "    'enable.auto.commit': True,\n",
        "    'fetch.min.bytes': 1,\n",
        "\n",
        "    'session.timeout.ms': 45000,\n",
        "}\n",
        "consumer = Consumer(conf)\n",
        "consumer.subscribe(['video-frames'])\n",
        "result_producer = Producer(conf)\n",
        "\n",
        "def send_result_to_kafka(score, label):\n",
        "    data = {\"score\": round(score, 4), \"label\": label}\n",
        "    result_producer.produce('detection-results', json.dumps(data).encode('utf-8'))\n",
        "    result_producer.flush()\n",
        "\n",
        "# Optimization Variables\n",
        "scores_history = []\n",
        "window_size = 10\n",
        "\n",
        "print(\"ðŸš€ NeuroLens AI Brain is LIVE. Processing Stream...\")\n",
        "\n",
        "# --- Main Loop ---\n",
        "try:\n",
        "    while True:\n",
        "        msgs = consumer.consume(num_messages=10, timeout=0.1)\n",
        "\n",
        "        if not msgs: continue\n",
        "\n",
        "        msg = msgs[-1]\n",
        "\n",
        "        if msg.error():\n",
        "            continue\n",
        "\n",
        "        frame_bytes = np.frombuffer(msg.value(), dtype=np.uint8)\n",
        "        frame = cv2.imdecode(frame_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if frame is not None:\n",
        "            img_rgb = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            face_img = mtcnn(img_rgb)\n",
        "\n",
        "            if face_img is not None:\n",
        "                # MTCNN Tensor to PIL\n",
        "                face_np = face_img.permute(1, 2, 0).cpu().numpy()\n",
        "                face_np = ((face_np + 1) * 127.5).astype(np.uint8)\n",
        "                face_pil = Image.fromarray(face_np)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    inputs = processor(images=face_pil, return_tensors=\"pt\").to(device)\n",
        "                    outputs = vit_model(**inputs)\n",
        "                    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "                    # prithivMLmods Indexing: 0 = Realism, 1 = Deepfake\n",
        "                    raw_fake_score = probs[0][1].item()\n",
        "\n",
        "                # Smoothing Logic\n",
        "                scores_history.append(raw_fake_score)\n",
        "                if len(scores_history) > window_size: scores_history.pop(0)\n",
        "                avg_score = sum(scores_history) / len(scores_history)\n",
        "\n",
        "                label = \"FAKE\" if avg_score > 0.5 else \"REAL\"\n",
        "                send_result_to_kafka(avg_score, label)\n",
        "\n",
        "                # UI Overlay\n",
        "                color = (0, 0, 255) if label == \"FAKE\" else (0, 255, 0)\n",
        "                cv2.putText(frame, f'{label}: {avg_score*100:.1f}%', (50, 50),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3)\n",
        "\n",
        "            cv2_imshow(frame)\n",
        "except Exception as e:\n",
        "    print(f\"Runtime Error: {e}\")\n",
        "finally:\n",
        "    consumer.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
